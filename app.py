import os
# --- 1. é…ç½®é•œåƒæº ---
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

import streamlit as st
import time
from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.document_loaders import DirectoryLoader, TextLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document

# --- 2. é¡µé¢è®¾ç½® ---
st.set_page_config(
    page_title="InfoStream - ä¸“ä¸šèµ„è®¯å½’æ¡£ç³»ç»Ÿ",
    page_icon="ğŸ“‘",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- 3. CSS æ·±åº¦å®šåˆ¶ (æµ…è“ä¸“ä¸šé£æ ¼) ---
st.markdown("""
<style>
    /* å…¨å±€èƒŒæ™¯ï¼šææ·¡çš„æµ·æ´‹è“ */
    .stApp {
        background-color: #F0F7FF;
    }
    
    /* ä¾§è¾¹æ ï¼šæµ…å¤©è“è‰²è°ƒ */
    [data-testid="stSidebar"] {
        background-color: #E3EEF9;
        border-right: 1px solid #D1E3F8;
    }
    
    /* æ ‡é¢˜æ ·å¼ï¼šæ·±æµ·è“ */
    h1, h2, h3 {
        color: #1A365D;
        font-family: 'Inter', 'Segoe UI', sans-serif;
    }
    
    /* æœç´¢ç»“æœé¡¹ï¼šç™½è‰²åº•è‰²ï¼Œå¸¦å¾®å¼±è“è‰²æŠ•å½± */
    .result-item {
        background-color: #FFFFFF;
        padding: 20px;
        margin-bottom: 15px;
        border-radius: 8px;
        border: 1px solid #E1E8F0;
        box-shadow: 0 2px 4px rgba(26, 54, 93, 0.05);
    }
    
    /* æœç´¢ç»“æœæ ‡é¢˜ï¼šæ›´å…·æ´»åŠ›çš„è“è‰² */
    .result-title {
        font-size: 1.15rem;
        font-weight: 600;
        color: #2B6CB0;
        margin-bottom: 6px;
    }
    
    /* å…ƒæ•°æ®ä¸æ ‡ç­¾ */
    .result-meta {
        font-size: 0.85rem;
        color: #718096;
        margin-bottom: 10px;
        font-family: 'SFMono-Regular', monospace;
    }
    
    .cat-tag {
        background-color: #EBF8FF;
        color: #2C5282;
        padding: 2px 10px;
        border-radius: 12px;
        font-size: 0.75rem;
        font-weight: 600;
        border: 1px solid #BEE3F8;
    }
    
    /* æ­£æ–‡æ‘˜è¦ */
    .result-snippet {
        font-size: 0.95rem;
        color: #2D3748;
        line-height: 1.6;
    }
    
    /* æŒ‰é’®æ ·å¼ï¼šå•†åŠ¡è“è‰² */
    div.stButton > button {
        border-radius: 6px;
        background-color: #3182CE;
        color: white;
        border: none;
        transition: all 0.3s ease;
    }
    div.stButton > button:hover {
        background-color: #2B6CB0;
        box-shadow: 0 4px 12px rgba(49, 130, 206, 0.3);
        transform: translateY(-1px);
    }

    /* è¾“å…¥æ¡†èšç„¦è‰² */
    .stTextInput input:focus {
        border-color: #3182CE !important;
    }
</style>
""", unsafe_allow_html=True)

# --- 4. æ ¸å¿ƒé€»è¾‘ ---
@st.cache_resource
def initialize_system():
    # æ³¨æ„ï¼šå¦‚æœæœ¬åœ°æ²¡æœ‰æ¨¡å‹ï¼Œä¼šè‡ªåŠ¨ä»é•œåƒä¸‹è½½
    embeddings = HuggingFaceEmbeddings(model_name="BAAI/bge-small-zh-v1.5")
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    if not os.path.exists('docs/'):
        os.makedirs('docs/')
    
    loader = DirectoryLoader('docs/', glob="**/*.txt", loader_cls=TextLoader, loader_kwargs={'encoding': 'utf-8'})
    raw_docs = loader.load()
    
    if not raw_docs:
        return None, None, []

    # è‡ªåŠ¨æ‰“æ ‡ç­¾é€»è¾‘
    categorized_docs = []
    ai_keywords = ['learning', 'neural', 'intelligence', 'gpt', 'python', 'data', 'cloud']
    fintech_keywords = ['blockchain', 'bitcoin', 'payment', 'finance', 'wallet', 'economy', 'bank']
    humanities_keywords = ['history', 'culture', 'art', 'philosophy', 'literature', 'civilization', 'museum']
    
    for doc in raw_docs:
        filename = doc.metadata['source'].lower()
        content = doc.page_content.lower()
        category = "General / Uncategorized"
        
        if any(k in filename or k in content for k in ai_keywords):
            category = "AI & Technology"
        elif any(k in filename or k in content for k in fintech_keywords):
            category = "FinTech & Economy"
        elif any(k in filename or k in content for k in humanities_keywords):
            category = "Humanities & History"
            
        doc.metadata['category'] = category
        categorized_docs.append(doc)

    fixed_categories = ["AI & Technology", "FinTech & Economy", "Humanities & History", "General / Uncategorized"]
    text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)
    splits = text_splitter.split_documents(categorized_docs)
    vector_db = FAISS.from_documents(splits, embeddings)
    
    return vector_db, raw_docs, fixed_categories

# --- 5. åˆå§‹åŒ– ---
with st.spinner("Initializing Azure Archive System..."):
    vector_db, raw_docs, category_list = initialize_system()

# --- 6. ä¾§è¾¹æ  ---
with st.sidebar:
    st.markdown("### ğŸ—‚ï¸ Navigator")
    selected_category = st.radio("Select Category:", ["ALL ARCHIVES"] + category_list)
    st.markdown("---")
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric(label="Total", value=len(raw_docs) if raw_docs else 0)
    with col2:
        if selected_category != "ALL ARCHIVES" and raw_docs:
            count = sum(1 for d in raw_docs if d.metadata.get('category') == selected_category)
            st.metric(label="Current", value=count)
        else:
            st.metric(label="Current", value="All")
    st.markdown("---")
    st.caption("System v2.1 | Azure Theme")

# --- 7. ä¸»ç•Œé¢ ---
st.markdown("## ğŸ” Information Retrieval System")
st.markdown("æ£€ç´¢å­˜æ¡£ä¸­çš„ä¸“ä¸šèµ„è®¯ä¸æ–‡æ¡£")

search_col1, search_col2 = st.columns([5, 1], vertical_alignment="bottom")
with search_col1:
    query = st.text_input("Search Query", placeholder="è¾“å…¥å…³é”®è¯ï¼Œä¾‹å¦‚ï¼šäººå·¥æ™ºèƒ½çš„å‘å±•...", label_visibility="collapsed")
with search_col2:
    search_btn = st.button("Search", use_container_width=True)

st.markdown("---")

# --- 8. æ£€ç´¢ä¸ç»“æœå±•ç¤º ---
if (query or search_btn) and vector_db:
    start_time = time.time()
    results = vector_db.similarity_search(query, k=15)
    
    if selected_category != "ALL ARCHIVES":
        filtered_results = [doc for doc in results if doc.metadata.get('category') == selected_category]
    else:
        filtered_results = results

    final_results = filtered_results[:5]

    if not final_results:
        st.warning(f"æœªåœ¨ ã€{selected_category}ã€‘ åˆ†ç±»ä¸­æ‰¾åˆ°ç›¸å…³å†…å®¹ã€‚")
    else:
        st.markdown(f"**æ‰¾åˆ° {len(final_results)} æ¡ç›¸å…³è®°å½•** (ç”¨æ—¶ {time.time() - start_time:.4f}s)")
        
        for doc in final_results:
            cat_tag = doc.metadata.get('category')
            file_name = doc.metadata['source'].split('/')[-1]
            full_file_path = doc.metadata['source']
            
            # æŸ¥æ‰¾åŸæ–‡
            full_content = "æœªæ‰¾åˆ°å…¨æ–‡å†…å®¹"
            for raw_doc in raw_docs:
                if raw_doc.metadata['source'] == full_file_path:
                    full_content = raw_doc.page_content
                    break

            # è“è‰²è°ƒåˆ—è¡¨æ˜¾ç¤º
            st.markdown(f"""
            <div class="result-item">
                <div class="result-title">ğŸ“„ {file_name}</div>
                <div class="result-meta">
                    <span class="cat-tag">{cat_tag}</span>
                    &nbsp; â€¢ &nbsp; âš–ï¸ ç›¸å…³åº¦åŒ¹é…
                </div>
                <div class="result-snippet">
                    {doc.page_content}... 
                </div>
            </div>
            """, unsafe_allow_html=True)
            
            with st.expander("ğŸ“– æŸ¥çœ‹å®Œæ•´æ–‡æ¡£"):
                st.markdown(full_content)
                st.caption(f"æ–‡ä»¶è·¯å¾„: {full_file_path}")

elif not vector_db:
    st.info("è¯·åœ¨ docs/ ç›®å½•ä¸‹æ”¾å…¥ .txt æ–‡ä»¶åå¯åŠ¨ç³»ç»Ÿã€‚")
elif not query:
    st.info("ğŸ’¡ æç¤ºï¼šåœ¨ä¸Šæ–¹æœç´¢æ¡†è¾“å…¥å†…å®¹ï¼Œæˆ–åœ¨å·¦ä¾§é€‰æ‹©åˆ†ç±»æµè§ˆã€‚")